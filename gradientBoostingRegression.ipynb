{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "from cleaning import clean_data\n",
    "from evaluate import qwk\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, VarianceThreshold\n",
    "\n",
    "from sklearn import ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training = (10495, 335)\n",
      "Testing = (4498, 335)\n"
     ]
    }
   ],
   "source": [
    "# Generating 3 datasets that reduce collinearity in the features\n",
    "# Load Data\n",
    "X_train, y_train, X_test, y_test = clean_data('')\n",
    "\n",
    "# PCA Decomposition\n",
    "pca = PCA(svd_solver='full')\n",
    "pcaX_train = pca.fit_transform(X_train)\n",
    "pcaX_test = pca.transform(X_test)\n",
    "\n",
    "# Select K Best\n",
    "kb = SelectKBest()\n",
    "kbX_train = kb.fit_transform(X_train, y_train)\n",
    "kbX_test = kb.transform(X_test)\n",
    "\n",
    "# Variance Threshold\n",
    "vt = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "vtX_train = vt.fit_transform(X_train, y_train)\n",
    "vtX_test = vt.transform(X_test)\n",
    "\n",
    "print(f'Training = {X_train.shape}')\n",
    "print(f'Testing = {X_test.shape}')\n",
    "# Create dict to store outcomes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= control ======================\n",
      "train acc: 0.2004869603016015\n",
      "test acc: 0.15395712010749807\n",
      "============= K best ======================\n",
      "train acc: 0.170004889558243\n",
      "test acc: 0.14088230357018072\n",
      "============= PCA Decomposition ======================\n",
      "train acc: 0.2501164710083923\n",
      "test acc: 0.11180560345203883\n",
      "============= Variance Threshold ======================\n",
      "train acc: 0.1894034186214375\n",
      "test acc: 0.1488303067115362\n"
     ]
    }
   ],
   "source": [
    "# Testing which dataset produces the best result on the linear regressor\n",
    "controlLogReg = ensemble.GradientBoostingRegressor()\n",
    "kbLogReg = ensemble.GradientBoostingRegressor()\n",
    "pcaLogReg = ensemble.GradientBoostingRegressor()\n",
    "vtLogReg = ensemble.GradientBoostingRegressor()\n",
    "\n",
    "controlLogReg.fit(X_train, y_train)\n",
    "kbLogReg.fit(kbX_train, y_train)\n",
    "pcaLogReg.fit(pcaX_train, y_train)\n",
    "vtLogReg.fit(vtX_train, y_train)\n",
    "\n",
    "print(\"============= control ======================\")\n",
    "print(\"train acc: \" + str(controlLogReg.score(X_train, y_train)))\n",
    "print(\"test acc: \" + str(controlLogReg.score(X_test, y_test)))\n",
    "\n",
    "print(\"============= K best ======================\")\n",
    "print(\"train acc: \" + str(kbLogReg.score(kbX_train, y_train)))\n",
    "print(\"test acc: \" + str(kbLogReg.score(kbX_test, y_test)))\n",
    "\n",
    "print(\"============= PCA Decomposition ======================\")\n",
    "print(\"train acc: \" + str(pcaLogReg.score(pcaX_train, y_train)))\n",
    "print(\"test acc: \" + str(pcaLogReg.score(pcaX_test, y_test)))\n",
    "\n",
    "print(\"============= Variance Threshold ======================\")\n",
    "print(\"train acc: \" + str(vtLogReg.score(vtX_train, y_train)))\n",
    "print(\"test acc: \" + str(vtLogReg.score(vtX_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 3. 3. ... 2. 2. 3.]\n",
      "[2. 3. 3. ... 2. 2. 3.]\n",
      "Acc without rounding: 1.227879057358826\n",
      "Acc with rounding: 1.227879057358826\n"
     ]
    }
   ],
   "source": [
    "# Trying a rounding function to sort the results into buckets\n",
    "# Using the best test result from the test above\n",
    "\n",
    "def roundGuess(guesses):\n",
    "    for i, guess in enumerate(guesses):\n",
    "        if guess < 0.5:\n",
    "            guesses[i] = 0\n",
    "        elif guess < 1.5:\n",
    "            guesses[i] = 1\n",
    "        elif guess < 2.5:\n",
    "            guesses[i] = 2    \n",
    "        elif guess < 3.5:\n",
    "            guesses[i] = 3\n",
    "        elif guess < 4.5:\n",
    "            guesses[i] = 4\n",
    "        else: guesses[i] = 5\n",
    "    return guesses     \n",
    "\n",
    "preds = controlLogReg.predict(X_test)\n",
    "roundedPreds = roundGuess(preds)\n",
    "\n",
    "print(\"Acc without rounding: \" + str(mean_squared_error(preds, y_test)))\n",
    "print(\"Acc with rounding: \" + str(mean_squared_error(roundedPreds, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t1\n",
      "0.007463090457218158\n",
      "0.04682182383238076\n",
      "0.11792963211745855\n",
      "0.13399694160461328\n",
      "0.14634336116149993\n",
      "0.14176281702237448\n",
      "\t2\n",
      "0.015511288142164514\n",
      "0.07871995326100567\n",
      "0.14443142805999398\n",
      "0.1520415732004542\n",
      "0.15387764774714752\n",
      "0.13282311323364648\n",
      "\t3\n",
      "0.018493198360860386\n",
      "0.09665569868957635\n",
      "0.15401421483429723\n",
      "0.15830683198204787\n",
      "0.14715817185513635\n",
      "0.024335937319792555\n",
      "\t4\n",
      "0.021455815662935862\n",
      "0.11085707019025626\n",
      "0.16009899389545446\n",
      "0.1604066554363962\n",
      "0.12783467234801416\n",
      "0.0014532542909005963\n",
      "\t5\n",
      "0.02353279661233132\n",
      "0.11805149999664277\n",
      "0.1618756872672782\n",
      "0.1620170367629966\n",
      "0.11945888933713589\n",
      "-0.2403040138126824\n",
      "\t6\n",
      "0.02491662628418756\n",
      "0.12155136666258715\n",
      "0.15978943104323018\n",
      "0.15489349528717355\n",
      "0.051888428598280134\n",
      "-0.30878954341207954\n",
      "\t7\n",
      "0.02640631671233229\n",
      "0.12492258989843896\n",
      "0.1549744243961595\n",
      "0.14708540560277494\n",
      "-0.03011852454628161\n"
     ]
    }
   ],
   "source": [
    "# Trying different learning rates and max depths on the regressor\n",
    "results = pd.DataFrame(columns=range(1,20))\n",
    "lrs = []\n",
    "for depth in range(1,20):\n",
    "    print(\"\\t\" + str(depth))\n",
    "    for lr in [0.001, 0.01, 0.1, 0.2, 0.5, 1]:\n",
    "        reg = ensemble.GradientBoostingRegressor(learning_rate=lr, max_depth=depth)\n",
    "        reg.fit(X_train, y_train)\n",
    "        print(reg.score(X_test, y_test))\n",
    "        lrs.append(reg.score(X_test, y_test))\n",
    "    # results[depth] = lrs\n",
    "print(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52427ff3b84206cb3d0491fd58946178d9bf6520d3aa33a25117d43f7acd7872"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
